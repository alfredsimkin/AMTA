import subprocess

print 'do not use fasta files precomputed by UCSC. Instead, upload the BED',
print 'file as a custom track and download the resulting coordinates as a fasta file',
print "with one fasta entry per gene, and including 5' UTR, cDNA, and 3' UTR exons but no introns"
#genome_species="['human', 'gorilla', 'orangutan', 'chimp', 'gibbon']"
genome_species="['human', 'gorilla', 'chimp', 'gibbon']"
maf_species_list="['hg19', 'gorGor3', 'panTro3', 'nomLeu1']"
data_folder='../test_data_folder/'
genome_paths=[data_folder+genome+'/' for genome in eval(genome_species)]
refseq_fasta_file='test_fasta'
refseq_bed_file='human_refseq_bed'
treefile=data_folder+'four_species'

'''
make_first_lastz_scripts.py operates on the genomes that make up your maf file. 
You will need to download each genome into a folder, and add the locations
of these genomes to genome_paths. Each folder should contain a 
genome, separated into at least 20 separate approximately equal sized fasta files 
(which can each have individual chromosomes or multiple chromosomes/contigs).
You will need to create a text file with a list of the names of these fasta files 
(one fasta file per line) called chromosome_list. This program creates a set
of lastz commands for each genome, which can be run in parallel or serially.
'''
#subprocess.call(['rm', data_folder+'lastz_commands'])
#for genome_folder in genome_paths:
#	subprocess.call(['python', 'make_first_lastz_scripts.py', data_folder, genome_folder, refseq_fasta_file+'_filtered'])

print 'you will now need to run all of the lastz commands from the "lastz_commands" script',
print 'within your data folder. You may want to parallelize these commands as each lastz command',
print 'can take up to a day to run. When finished, continue on to main_script3.py'
#exit()
'''
After running these lastz commands on each fasta file of a genome, 
join_result_files.py joins the output from each lastz run into one result 
file, so that each genome has a separate, single result file.
'''
#for genome_folder in genome_paths:
#	subprocess.call(['python', 'join_result_files.py', genome_folder])

'''
parse_results2.py goes through the result file generated by 
join_result_files.py (stored as a set of statistics for each alignment) and 
organizes the alignments into putative transcripts. This program removes 
alignments that have below 95% identity to the human subject sequences, and 
considers transcripts to be those alignments which fall on the same strand 
of the same chromosome, and which match the chromosome in the same order as 
the searched subject gene (ex. if part of exon 3 matches genomic position 
10 of the positive strand of chromosome 1, the next hit, to a higher 
position on the positive strand of chromosome 1, should be to exon 4 or a 
subsequent position in exon 3, and not exon 2). These multiple 
'transcript' alignments are then ranked by total percent of subject gene 
sequence covered. Only those which cumulatively cover more than 80% of the 
subject human gene are included. Of these, only those which have a second 
best hit that covers less than 20% of the material covered by the best hit 
are considered. Of this set, only those having less than 20% of their 
subject sequence covered redundantly by the alignments are considered, and 
finally, the transcript is compared to the UCSC file with UTR exons in 
lowercase to remove any transcripts which cover any 3' UTR basepairs 
redundantly. The protein coding genes which remain after these filters are 
written to a dictionary.
'''
#for genome_folder in genome_paths:
#	subprocess.call(['python', 'parse_results2.py', genome_folder, data_folder+refseq_fasta_file+'_filtered', data_folder+refseq_bed_file+'_filtered'])
'''
merge_them.py takes the output dictionaries from each genome created by 
parse_results2.py, and intersects them with each other. The result is a 
list of putatively non-duplicated genes with high confidence of homology 
to the human genome across all primates.
'''
#subprocess.call(['python', 'merge_them.py', str(genome_paths), data_folder])

'''
get_lastz_hits.py filters the output of coordinate_converter.py to only 
list results retrieved by merge_them.py.
'''
#subprocess.call(['python', 'get_lastz_hits.py', data_folder, refseq_bed_file])
'''
final_filter.py takes the list of genes retrieved by get_lastz_hits.py, 
the maf entries from extract_only_all_species.py, and the summaries from 
extract_only_all_species.py, filters out any maf entries that overlap the 
3' UTRs redundantly or change their strand of homology within the same 
protein coding gene, pieces together the sequence corresponding to these 
3' UTRs covered by these maf entries (with 5 N's inserted between 
nonadjacent regions of 3' UTR), and runs dnaml on the results (using 
collect_ancestors.py to store the dnaml results in a dictionary and verify 
that the tree topology is consistent across dnaml runs)
'''
#subprocess.call(['python', 'final_filter2.py', data_folder, refseq_bed_file, genome_species, maf_species_list])

'''
remove_gaps.py replaces runs of one or more ambiguous nucleotides in one 
or more lineages with a single ambiguous nucleotide in all lineages. This 
is done to ensure that only those 8mers which are unambiguous in all 
lineages are analyzed.
'''
#subprocess.call(['python', 'remove_gaps.py', data_folder, genome_species, 'final_utr_dictionary'])
#subprocess.call(['rm', data_folder+'final_utr_dictionary'])


'''
make_ancestors.py runs dnaml on 'final_utr_dictionary' to recover
ancestral states in a nucleotide by nucleotide fashion. The output is a
dictionary of ancestral states
'''
subprocess.call(['cp', treefile, 'intree'])
subprocess.call(['python', 'make_ancestors.py', data_folder, genome_species])

'''
remove_gaps.py replaces runs of one or more ambiguous nucleotides in one 
or more lineages with a single ambiguous nucleotide in all lineages. This 
is done to ensure that only those 8mers which are unambiguous in all 
lineages are analyzed.
'''
subprocess.call(['python', 'remove_gaps.py', data_folder, genome_species, 'ancestor_dictionary'])
subprocess.call(['rm', data_folder+'ancestor_dictionary'])
